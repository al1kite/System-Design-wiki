## 사용자 수에 따른 규모 확장

사용자가 늘어남에 따라 어떻게 시스템이 확장되는지 설명.
일반적으로 분산 시스템을 구성하는 위치까지 가려면 꽤 대규모 시스템이 운영되고 있음을 의미한다.

0명부터 대규모 시스템까지 도달하는 중간 과정에 어떤 컴포넌트가 개입될 수 있는지 대략적으로 살펴볼 예정.

일단 초반에 데이터베이스를 분리하기 전 시스템부터 이야기해볼 생각.
최근에는 사용자가 한 명이어도 이런 방식으로 시작하지는 않는 것 같다.
최근 SQLite 같은 로컬 데이터베이스 시스템도 빠르게 발전하고 있기는 하다.
유저가 많지 않다면, 또는 일정할 거라고 예상된다면 DB나 웹서버를 확장해야 될 필요가 없으므로
로컬 데이터베이스를 선택하는 것도 좋은 선택이 될 것 같다.
단순하게 서버 한 대가 있는 모습이 될 것. 이에 대한 내용은 많이 할 게 없고
데이터베이스 선택 (NoSQL, RDB) 해야한다. 

일단 NoSQL과 RDB 중 어떤 스토리지를 선택해야할까?
대부분은 RDB가 적합한 상황일 것.
RDB는 비교적 오랜 시간 동안 많은 유즈 케이스를 담당하며 발전해왔다.
하지만 더 가용성 높은 시스템이 요구되면서 NoSQL 같은 솔루션이 등장하게 된 것.

다음과 같은 상황이라면 `NoSQL을 도입할 수도 있다` 이렇게 검토할 수 있다.

**NoSQL 고려사항**
- 낮은 Latency 필요한 경우
- 비구조화된 데이터를 다루거나 관계형 데이터가 불필요한 경우
- 데이터 직렬화 & 역직렬화에 초점을 맞춘 경우
- 대규모 쓰기 작업이 필요한 경우

RDB의 경우 범용적인 유즈케이스를 충족하기 위한 방향으로 발전해 온 반면에 
NoSQL의 경우 특수한 목적을 갖고있는 경우가 많다.
물론 MongoDB와 같이 범용적인 목표를 충족하는 경우도 있는데
각자 잘하는 것들이 다른 경우가 많다.
어떤 데이터베이스를 선택할지는 설계하는 시스템 요구사항에 따라서 어떤 DB를 선택할지 고민해볼 필요가 있다.

어찌됐든 우리는 시스템을 담당하는 서버와 데이터베이스를 처리하는 데이터베이스 서버 이렇게 두개의 컴포넌트로 현재 시스템을 구성한 상태이다.

### Scale Up & Scale Out

#### Scale Up
스케일 아웃과 스케일 업에 대해 잠깐 이야기를 할 건데 둘다 부하를 처리하기 위한 방법이다.
일반적으로 더 쉬운 방법은 스케일 업인데, 스케일 업은 단순히 서버 인스턴스의 스펙을 더 좋게 만드는 방법이다.
이 방법은 서비스에 별 다른 변화를 요구하지 않기 때문에 선택하기 굉장히 쉽다.

하지만 서비스 같은 경우는 계속해서 성장하는 편이니까 스케일 업에는 어느 정도 한계가 있다.
컴퓨팅 인스턴스 자원, CPU나 RAM 같은게 지수적으로 비싸지기 때문에
어느 정도 규모가 지나면 감당하기 어려운 수준의 비용을 요구한다.
따라서 서비스가 지속적으로 규모가 커지는게 아니라면 스케일 업으로 해결할 수 있지만
그렇지 않다면 일종의 임시방편일 뿐인 것.

#### Scale Out
서비스를 위한 서버를 스케일 아웃 가능하도록 만들려면 서비스의 동작이 멱등적이어야 하며 상태를 관리하지 않는 서버가 되어야 한다.
무상태성이 되어야 한다는 뜻인데, 여러 서버가 하나의 서비스를 위해 동작하는 상황인데 
각 서버가 상태를 각자 관리하게 되면 상태의 파편화가 발생할 수 있다.
즉, 어떤 서버로 요청을 보냈는지에 따라서 응답 결과가 달라질 수 있다는 것을 의미한다.
이렇게 무상태성 서비스를 만드는 것이 스케일 아웃의 첫 번째 요구사항이다.
REST API라고 불리는 어떤 스펙의 가장 중요한 성질 중 하나.
멱등적이라는 말은 어떤 서비스에 어떤 요청을 보냈을 때 이때 여러 번 보내도 동일한 동작을 수행하는 걸 멱등적이라고 한다.
예를 들어 "데이터베이스의 특정 값에 +1 한 결과를 보여줘" 라고 하는 API 가 있다면 이는 멱등적이지 않다.
매변 결과 때마다 +1 결과를 보여주기 때문.
반면에 "X라는 정수값을 보내면 그 값에 +1 한 결과를 알려줘" 로 동작하는 서버는 역등적으로 동작하는 서버인 것.

#### Load Balance
이렇게 무상태성 서버를 여럿 띄우게 되면 그 앞단에 로드 밸런스라고 하는 컴포넌트를 도입할 수 있게 된다.
로드 밸런스는 여러 서버로 특정 규칙에 맞게 부하를 분산해준다. 대표적인 방법은 라운드 로빈이 가장 유명.

라운드 로빈은 평등하게 어떤 서버가 2대 있으면 순서대로 부하를 분산해주는 방법이고 
스티키 방식이라고 해서 특정 규칙을 따라 특정 서버로 보낸다던지 하는 방식도 있다.
이런 많은 전략을 따를 수 있는데 무상태성을 띄게 되었을 때는 로드 밸런스가 일반적으로 앞에 붙어서 
부하를 여러 서버로 분산해주는 역할을 한다.

이제 서버를 수평 확장하는 방식으로 부하를 분산할 수 있고 서비스가 안정적으로 돌아갈 수 있지만
데이터베이스 자체의 Read Latency 가 증가할 수 있다.
많은 서비스가 데이터를 요청하게 되면 그렇게 될 것.
데이터베이스의 부하가 감당하기 어려울 정도로 늘어나는 상황이 되면 추가적인 조치가 필요하다.

### Cache
이때 캐시는 읽기 부하를 줄이는 훌륭한 도구이다.
데이터베이스는 영구 저장소 레이어에 해당하기 때문에 디스크, SSD에 읽고 쓰는 작업을 수행한다.
물론 DB는 기본적으로 OS 캐시 시스템 또는 DB 자체 읽기 캐시를 사용하지만
처리량 자체가 감당하기 어려운 수준으로 들어오는 경우 결국 DB까지 흘러오는 처리량 자체를 줄여줄 필요가 있다.

우리가 흔히 사용하는 캐시는 보통 메모리에 저장된다.
Redis나 Memcache 등 In-memory DB 솔루션을 많이 사용하게 되는데
하지만 위에서 언급한 것처럼 메모리는 무한하지 않다.
용량이 커질 수록 값은 지수 상승한다. 따라서 우리는 모든 데이터를 캐시에 담아둘 수 없고
아주 전략적으로 캐시를 사용해야 한다.

우리가 캐시를 도입한 다음, 캐시에서 데이터를 읽어올 수 있게 되는 경우를 Cache Hit 이라 부르고
만약 메모리를 들렸는데 캐시에 데이터가 없다면 Cache Miss 라 부른다.
결국 우리는 Cache Hit을 올릴 수 있는 방향으로 캐시를 설계해야 되는 것.

가장 일반적인 캐시 활용 전략이 Read Through 정책인데 이 정책은 캐시를 먼저 확인하고 찾고자 하는 데이터가 없는 경우
원본 데이터에서 이를 가지고 온다. 즉 Cache Miss의 경우 네트워크 홉이 하나 추가될 수 있기 때문에 
Cache Hit이 발생하지 않으면 오히려 시스템이 느려진다.
따라서 Cache Hit 비율을 높이면서 비용 측면을 고려하며 캐시를 운영할 때 다음 포인트들을 고민해볼 수 있을 것 같다.

#### Cache : 무엇을 담을 것인가?

일단 무엇을 담을 것인가를 고민할 필요가 있다.

캐시에 담아야 하는 것들은 연산이 오래 걸리는 것, 예를 들면 머신 러닝 결과나 지리 정보 연산 결과 등이 있을 것이다.
그리고 I/O가 오래 걸리는 것, 변경이 적고 자주 접근하는 것이 적합하다.

그리고 또 고민해야하는 건 언제 무효화 할 건 지인데, Invalidation, 무효화 정책이라고 불리는 걸 고민할 필요가 있다. 
모든 캐시 데이터는 적절한 만료 시기가 필요하다.
만약 이 기간이 너무 길면 원본 데이터가 바뀌었을 때 오래된 데이터를 보여줄 수 있고
너무 짧으면 Cachhe Miss 가 발생할 수 있다.

캐시에 저장되는 데이터의 일관성에 대한 문제도 고민할 필요가 있다.
일관성에서 고민할 점은 원본 데이터와 동기화되지 않은 데이터인데,
보통 오래된 데이터를 캐시가 가지고 있게 되는 것을 의미한다. 
일관성을 위해서라면 원본 데이터를 수정할 때 캐시도 같이 업데이트 해줘야 한다.
하지만 데이터를 업데이트 할 때 동시성 문제로 잘못된 값을 캐시에서 바라보고 있을 수도 있다.

예를 들어 A 라는 서버가 데이터 D를 업데이트 한 다음에 값을 다시 캐시에서 쓰기 전에
B 라는 서버가 이를 삭제하거나 다른 값으로 바꾼 다음 A에서 수정한 결과가 캐시에 도달하기 전에
캐시에 B가 수정한 결과의 요청이 먼저 도달해서 D에 대한 값을 수정하는 경우,
캐시에는 일정 기간 동안 오래된 데이터 혹은 잘못된 데이터가 저장된다.

따라서 이를 막기 위해 멱등적인 동작을 하는 캐시 삭제를 보통 선택하는 편이다.
나중에 읽어올 때 Cache Miss를 발생시킬 순 있지만 일관성 문제를 완화하기 위함.

이렇게 분산 시스템에서는 문제와 요구사항에 따른 선택적 대응이 필요하다.

#### Cache : 장애 대처

일반적으로 캐시에 장애가 발생하더라도 서비스는 죽지 않아야 되는게 맞다.
서비스 로직에서 에러가 발생하지 않도록 해야 되는데 캐시 장애가 나는 경우 그 뒤쪽으로 부하가 흘러 넘치게 될 것.
이를 방어하기 위해서는 뒤쪽에 서비스 역시 오토스케일링 같은 방식으로 확장성에 대해 충분히 대비하고 있는 것이 좋다.

또한 캐시 서버 자체의 가용성이 높아지도록 분산 캐시를 구성하는 방법도 있다.

#### Cache : 축출 정책 (Eviction Policy)

캐시 공간이 부족할 때 잘 사용되지 않는 데이터를 축출해내야 된다.
이때 캐시 알고리즘이 사용된다. 가장 많이 사용되는 방법은 Leat Recently Used 라고
LRU 라고 많이 알려진 방법이다. 가장 최근에 사용되지 않는 아이템을 삭제하는 방법이다.
보통 이 정책은 우리가 직접 만들기 보다는 사용 중인 캐시 서버가 제공하는 알고리즘에 의존적.

#### Cahce : 캐시 사이즈

지금까지 설명한 방법들을 충분히 적용하고도 추가적으로 캐시 장애가 발생하지 않도록 하는
가장 쉽고 좋은 방법은 캐시 메모리를 충분하게 주는 것.
약간 돈으로 막는 느낌이지만 이것도 가능하다면 정말 훌륭한 대응책이라 생각.

캐시 사이즈를 선택할 때 고려해야할 점은 전체 데이터 양, 캐시 대상 선정 정책, 예상되는 캐시 Hit 비율 등이 있을 수 있다.

지금까지 캐시 서버를 DB 앞단에 두는 것까지 보았다.
꼭 데이터베이스가 아니더라도 특정 서비스가 응답이 지연된다면 캐시를 사용할 수 있다.

### Scaling DB (데이터베이스 확장)

캐시 뒤쪽의 서비스도 캐시 장애를 대비해서 가용성 있는 구성을 하는 것이 좋다.
데이터베이스는 상태를 저장하기 때문에 스케일링이 조금 어려운 편이다.
가장 일반적인 방법으로 복제와 샤딩이 있다.

#### Scaling DB : 복제 (Replication)

복제란 보통 Active (Leader, Master) 데이터베이스를 하나 두고 Passive (Follower, Slave) 데이터베이스를 생성한다.
엑티브 데이터베이스는 쓰기를 담당하고 나머지는 쓰기 변경점을 복제하는 구조이다.
그래서 쓰기 직후 읽기를 했을 때 일관된 데이터를 보지 못하는 경우가 발생할 수 있다.
예를 들어 Active에 쓰기를 수행한 다음 Passive DB를 읽는 것.
그랬을 때 요청자는 일관적이지 않은 데이터를 볼 수 있고 이는 일종의 일관성 문제인데 
데이터베이스에 일관성 문제 해결 레벨에 따라서 강한 일관성을 지원하는 경우 항상 일관된 데이터를 읽을 수도 있지만
이런 경우 가용성이 높은 경우는 아니라고 할 수 있다.
하지만 읽기 부하를 분산할 수 있다는 점에서 여전히 유용하다.
반면에 약한 일관성을 지원하고 있다면 사용자는 비교적 빠르게 데이터에 접근하면서 읽기 부하를 분산시킬 수 있다.

#### Scaling DB : 샤딩 (Sharding)

샤딩은 DB가 담당하는 영역을 나눠 부하가 나눠지도록 하는 방법이다.
예를 들어 유저으 아이디가 홀수인 경우 A 스토리지, 짝수인 경우 B 스토리지로 전달한다든지, 
쇼핑 카드 서비스인 경우 A 스토리지로, 이벤트 서비스인 경우 B 시트로지로 보낸다든지와 같은 식으로
요청을 처리하는 주체를 나누는 것이다.

따라서 각 나너진 영역에 대한 쓰기를 담당하게 된다.
복제와 샤딩에 대한 얘기는 장애가 발생했을 때 어떻게 할 것인지를 
설명하는 것이 굉장히 큰 주제라 생각.

<img width="825" src="https://github.com/al1kite/System-Design-wiki/assets/102217402/36ea9d18-63ea-4495-96df-a00c07134bf9">


### 후반 : Global 서비스 운영

지금까지의 구성만으로도 웬만한 서비스를 커버할 수 있다고 생각하는데
Global 서비스로 운영된다 가정할 때, 서비스를 이용할 때 지연을 줄이기 위해 지금까지의 구성을
각 지역에 가깝게, 그러니까 여러 지역에 배포하게 된다.
AWS 에서 리전마다 데이터 센터를 만드는 걸 생각해보면 좋을 듯.

따라서 후반 내용은 지구 여러 곳에서 만들어진 데이터 센터를 어떻게 운영할지에 대한 내용이다.
이 수준은 많이 없기도 하고 서비스 특징에 따라 정말 다양한 해결책을 사용하고 있다.

보통 데이터 센터를 가용 지역 여러 개에 두는 경우
서비스가 자연 재해 혹은 정전 같은 상황에서 견고하게 서비스를 유지할 수 있다.

하지만 장애 시 가용 지역의 부하를 다른 지역에서 버텨야 하므로 
이런 가용성을 유지하기 위한 노하우가 필요하다.

이런 내용을 케이스 스터디로 살펴볼 예정.

#### 함께 보면 좋은 자료

https://bytebytego.com/courses/system-design-interview/scale-from-zero-to-millions-of-users

